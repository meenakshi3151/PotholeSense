{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajdonLytgtWg",
        "outputId": "30e2ddea-1e23-4dc0-da64-a1f4751b33c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n",
            "Total samples: 9859\n",
            "Missing values:\n",
            "timestamp         0\n",
            "latitude          0\n",
            "longitude         0\n",
            "speed             0\n",
            "accelerometerX    0\n",
            "accelerometerY    0\n",
            "accelerometerZ    0\n",
            "gyroX             0\n",
            "gyroY             0\n",
            "gyroZ             0\n",
            "pothole           0\n",
            "trip_id           0\n",
            "dtype: int64\n",
            "\n",
            "Removing outliers...\n",
            "Samples after outlier removal: 9859\n",
            "\n",
            "Standardizing features...\n",
            "\n",
            "Original class distribution:\n",
            "pothole\n",
            "0    9348\n",
            "1     511\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balancing classes with RandomOverSampler...\n",
            "Balanced class distribution:\n",
            "pothole\n",
            "0    9348\n",
            "1    9348\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train set size: 14956\n",
            "Test set size: 3740\n",
            "\n",
            "======================================================================\n",
            "TRAINING ADVANCED MODELS FOR POTHOLE DETECTION\n",
            "======================================================================\n",
            "\n",
            "[1/5] Training XGBoost...\n",
            "[2/5] Training LightGBM...\n",
            "[3/5] Training CatBoost...\n",
            "[4/5] Training Bagging Classifier...\n",
            "[5/5] Training 1D-CNN...\n",
            "\n",
            "======================================================================\n",
            "MODEL EVALUATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "XGBoost:\n",
            "--------------------------------------------------\n",
            "  Training Accuracy: 0.9702\n",
            "  Test Accuracy:     0.9604\n",
            "  Test F1 Score:     0.9618\n",
            "  Overfitting Gap:   0.0098\n",
            "\n",
            "LightGBM:\n",
            "--------------------------------------------------\n",
            "  Training Accuracy: 0.9700\n",
            "  Test Accuracy:     0.9612\n",
            "  Test F1 Score:     0.9625\n",
            "  Overfitting Gap:   0.0087\n",
            "\n",
            "CatBoost:\n",
            "--------------------------------------------------\n",
            "  Training Accuracy: 0.9373\n",
            "  Test Accuracy:     0.9283\n",
            "  Test F1 Score:     0.9319\n",
            "  Overfitting Gap:   0.0089\n",
            "\n",
            "Bagging:\n",
            "--------------------------------------------------\n",
            "  Training Accuracy: 0.9745\n",
            "  Test Accuracy:     0.9687\n",
            "  Test F1 Score:     0.9697\n",
            "  Overfitting Gap:   0.0058\n",
            "\n",
            "1D-CNN:\n",
            "--------------------------------------------------\n",
            "  Training Accuracy: 0.9689\n",
            "  Test Accuracy:     0.9489\n",
            "  Test F1 Score:     0.9514\n",
            "  Overfitting Gap:   0.0200\n",
            "\n",
            "======================================================================\n",
            "FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Model Rankings (by F1 Score):\n",
            "--------------------------------------------------\n",
            "1. Bagging         - F1: 0.9697, Accuracy: 0.9687\n",
            "2. LightGBM        - F1: 0.9625, Accuracy: 0.9612\n",
            "3. XGBoost         - F1: 0.9618, Accuracy: 0.9604\n",
            "4. 1D-CNN          - F1: 0.9514, Accuracy: 0.9489\n",
            "5. CatBoost        - F1: 0.9319, Accuracy: 0.9283\n",
            "\n",
            "üèÜ BEST MODEL: Bagging\n",
            "--------------------------------------------------\n",
            "Test Accuracy:  0.9687\n",
            "Test F1 Score:  0.9697\n",
            "Training Acc:   0.9745\n",
            "\n",
            "Confusion Matrix (Bagging):\n",
            "[[1753  117]\n",
            " [   0 1870]]\n",
            "\n",
            "Classification Report (Bagging):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  No Pothole       1.00      0.94      0.97      1870\n",
            "     Pothole       0.94      1.00      0.97      1870\n",
            "\n",
            "    accuracy                           0.97      3740\n",
            "   macro avg       0.97      0.97      0.97      3740\n",
            "weighted avg       0.97      0.97      0.97      3740\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SAVING MODELS\n",
            "======================================================================\n",
            "‚úì Best model saved as 'best_pothole_detection_model_bagging.joblib'\n",
            "‚úì XGBoost saved as 'pothole_model_xgboost.joblib'\n",
            "‚úì LightGBM saved as 'pothole_model_lightgbm.joblib'\n",
            "‚úì CatBoost saved as 'pothole_model_catboost.joblib'\n",
            "‚úì Bagging saved as 'pothole_model_bagging.joblib'\n",
            "‚úì Scaler saved as 'scaler.joblib'\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "trip1_potholes = pd.read_csv('trip1_potholes.csv')\n",
        "trip1_sensors = pd.read_csv('trip1_sensors.csv')\n",
        "trip2_potholes = pd.read_csv('trip2_potholes.csv')\n",
        "trip2_sensors = pd.read_csv('trip2_sensors.csv')\n",
        "trip3_potholes = pd.read_csv('trip3_potholes.csv')\n",
        "trip3_sensors = pd.read_csv('trip3_sensors.csv')\n",
        "trip4_potholes = pd.read_csv('trip4_potholes.csv')\n",
        "trip4_sensors = pd.read_csv('trip4_sensors.csv')\n",
        "trip5_potholes = pd.read_csv('trip5_potholes.csv')\n",
        "trip5_sensors = pd.read_csv('trip5_sensors.csv')\n",
        "\n",
        "# Convert timestamps\n",
        "for df in [trip1_sensors, trip1_potholes]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "for df in [trip2_sensors, trip2_potholes]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "for df in [trip3_sensors, trip3_potholes]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "for df in [trip4_sensors, trip4_potholes]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "for df in [trip5_sensors, trip5_potholes]:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "\n",
        "# Label pothole events for trip 1\n",
        "trip1_sensors['pothole'] = 0\n",
        "for pothole_time in trip1_potholes['timestamp']:\n",
        "    mask = (trip1_sensors['timestamp'] >= pothole_time - pd.Timedelta(seconds=0.5)) & \\\n",
        "           (trip1_sensors['timestamp'] <= pothole_time + pd.Timedelta(seconds=0.5))\n",
        "    trip1_sensors.loc[mask, 'pothole'] = 1\n",
        "\n",
        "# Label pothole events for trip 2\n",
        "trip2_sensors['pothole'] = 0\n",
        "for pothole_time in trip2_potholes['timestamp']:\n",
        "    mask = (trip2_sensors['timestamp'] >= pothole_time - pd.Timedelta(seconds=0.5)) & \\\n",
        "           (trip2_sensors['timestamp'] <= pothole_time + pd.Timedelta(seconds=0.5))\n",
        "    trip2_sensors.loc[mask, 'pothole'] = 1\n",
        "\n",
        "# Label pothole events for trip 3\n",
        "trip3_sensors['pothole'] = 0\n",
        "for pothole_time in trip3_potholes['timestamp']:\n",
        "    mask = (trip3_sensors['timestamp'] >= pothole_time - pd.Timedelta(seconds=0.5)) & \\\n",
        "           (trip3_sensors['timestamp'] <= pothole_time + pd.Timedelta(seconds=0.5))\n",
        "    trip3_sensors.loc[mask, 'pothole'] = 1\n",
        "\n",
        "# Label pothole events for trip 4\n",
        "trip4_sensors['pothole'] = 0\n",
        "for pothole_time in trip4_potholes['timestamp']:\n",
        "    mask = (trip4_sensors['timestamp'] >= pothole_time - pd.Timedelta(seconds=0.5)) & \\\n",
        "           (trip4_sensors['timestamp'] <= pothole_time + pd.Timedelta(seconds=0.5))\n",
        "    trip4_sensors.loc[mask, 'pothole'] = 1\n",
        "\n",
        "# Label pothole events for trip 5\n",
        "trip5_sensors['pothole'] = 0\n",
        "for pothole_time in trip5_potholes['timestamp']:\n",
        "    mask = (trip5_sensors['timestamp'] >= pothole_time - pd.Timedelta(seconds=0.5)) & \\\n",
        "           (trip5_sensors['timestamp'] <= pothole_time + pd.Timedelta(seconds=0.5))\n",
        "    trip5_sensors.loc[mask, 'pothole'] = 1\n",
        "\n",
        "# Add trip IDs\n",
        "trip1_sensors['trip_id'] = 1\n",
        "trip2_sensors['trip_id'] = 2\n",
        "trip3_sensors['trip_id'] = 3\n",
        "trip4_sensors['trip_id'] = 4\n",
        "trip5_sensors['trip_id'] = 5\n",
        "\n",
        "# Combine all trips\n",
        "all_trips = pd.concat([\n",
        "    trip1_sensors, trip2_sensors, trip3_sensors,\n",
        "    trip4_sensors, trip5_sensors\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(f\"Total samples: {len(all_trips)}\")\n",
        "print(f\"Missing values:\\n{all_trips.isna().sum()}\")\n",
        "\n",
        "# Remove outliers\n",
        "print(\"\\nRemoving outliers...\")\n",
        "all_trips = all_trips[(all_trips['accelerometerX'] < 10) & (all_trips['accelerometerX'] > -10)]\n",
        "all_trips = all_trips[(all_trips['accelerometerY'] < 10) & (all_trips['accelerometerY'] > -10)]\n",
        "all_trips = all_trips[(all_trips['accelerometerZ'] < 10) & (all_trips['accelerometerZ'] > -10)]\n",
        "all_trips = all_trips[(all_trips['gyroX'] < 10) & (all_trips['gyroX'] > -10)]\n",
        "all_trips = all_trips[(all_trips['gyroY'] < 10) & (all_trips['gyroY'] > -10)]\n",
        "all_trips = all_trips[(all_trips['gyroZ'] < 10) & (all_trips['gyroZ'] > -10)]\n",
        "print(f\"Samples after outlier removal: {len(all_trips)}\")\n",
        "\n",
        "# Feature engineering\n",
        "all_trips['acclermeter_magnitude'] = (all_trips['accelerometerX']**2 + all_trips['accelerometerY']**2 + all_trips['accelerometerZ']**2)**0.5\n",
        "all_trips['gyro_magnitude'] = (all_trips['gyroX']**2 + all_trips['gyroY']**2 + all_trips['gyroZ']**2)**0.5\n",
        "\n",
        "features = ['latitude', 'longitude', 'speed', 'accelerometerX',\n",
        "           'accelerometerY', 'accelerometerZ', 'gyroX', 'gyroY', 'gyroZ',\n",
        "           'acclermeter_magnitude', 'gyro_magnitude']\n",
        "\n",
        "# Standardize features\n",
        "print(\"\\nStandardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "all_trips[features] = scaler.fit_transform(all_trips[features])\n",
        "\n",
        "# Check class distribution\n",
        "print(f\"\\nOriginal class distribution:\\n{all_trips['pothole'].value_counts()}\")\n",
        "\n",
        "# Handle class imbalance\n",
        "print(\"\\nBalancing classes with RandomOverSampler...\")\n",
        "X = all_trips[features]\n",
        "y = all_trips['pothole']\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X, y = ros.fit_resample(X, y)\n",
        "print(f\"Balanced class distribution:\\n{y.value_counts()}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "print(f\"\\nTrain set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# ==================== ADVANCED MODELS ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING ADVANCED MODELS FOR POTHOLE DETECTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. XGBoost\n",
        "print(\"\\n[1/5] Training XGBoost...\")\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# 2. LightGBM\n",
        "print(\"[2/5] Training LightGBM...\")\n",
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# 3. CatBoost\n",
        "print(\"[3/5] Training CatBoost...\")\n",
        "from catboost import CatBoostClassifier\n",
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# 4. Bagging Classifier\n",
        "print(\"[4/5] Training Bagging Classifier...\")\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=10),\n",
        "    n_estimators=50,\n",
        "    max_samples=0.8,\n",
        "    max_features=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 5. 1D-CNN\n",
        "print(\"[5/5] Training 1D-CNN...\")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_1d_cnn(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Reshape((input_shape[0], 1)),\n",
        "        layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = create_1d_cnn((X_train.shape[1],))\n",
        "\n",
        "# Train and evaluate all models\n",
        "models = {\n",
        "    'XGBoost': xgb_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'CatBoost': catboost_model,\n",
        "    'Bagging': bagging_model,\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(\"-\" * 50)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    test_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"  Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"  Test Accuracy:     {test_acc:.4f}\")\n",
        "    print(f\"  Test F1 Score:     {test_f1:.4f}\")\n",
        "    print(f\"  Overfitting Gap:   {(train_acc - test_acc):.4f}\")\n",
        "\n",
        "    results[model_name] = {\n",
        "        'model': model,\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'f1': test_f1,\n",
        "        'predictions': y_pred_test\n",
        "    }\n",
        "\n",
        "# Train 1D-CNN\n",
        "print(f\"\\n1D-CNN:\")\n",
        "print(\"-\" * 50)\n",
        "history = cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# CNN Predictions\n",
        "y_pred_train_cnn = (cnn_model.predict(X_train, verbose=0) > 0.5).astype(int).flatten()\n",
        "y_pred_test_cnn = (cnn_model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()\n",
        "\n",
        "train_acc_cnn = accuracy_score(y_train, y_pred_train_cnn)\n",
        "test_acc_cnn = accuracy_score(y_test, y_pred_test_cnn)\n",
        "test_f1_cnn = f1_score(y_test, y_pred_test_cnn)\n",
        "\n",
        "print(f\"  Training Accuracy: {train_acc_cnn:.4f}\")\n",
        "print(f\"  Test Accuracy:     {test_acc_cnn:.4f}\")\n",
        "print(f\"  Test F1 Score:     {test_f1_cnn:.4f}\")\n",
        "print(f\"  Overfitting Gap:   {(train_acc_cnn - test_acc_cnn):.4f}\")\n",
        "\n",
        "results['1D-CNN'] = {\n",
        "    'model': cnn_model,\n",
        "    'train_acc': train_acc_cnn,\n",
        "    'test_acc': test_acc_cnn,\n",
        "    'f1': test_f1_cnn,\n",
        "    'predictions': y_pred_test_cnn\n",
        "}\n",
        "\n",
        "# Find best model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Sort by F1 score\n",
        "sorted_results = sorted(results.items(), key=lambda x: x[1]['f1'], reverse=True)\n",
        "\n",
        "print(\"\\nModel Rankings (by F1 Score):\")\n",
        "print(\"-\" * 50)\n",
        "for i, (model_name, metrics) in enumerate(sorted_results, 1):\n",
        "    print(f\"{i}. {model_name:15} - F1: {metrics['f1']:.4f}, Accuracy: {metrics['test_acc']:.4f}\")\n",
        "\n",
        "best_model_name = sorted_results[0][0]\n",
        "best_metrics = sorted_results[0][1]\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Test Accuracy:  {best_metrics['test_acc']:.4f}\")\n",
        "print(f\"Test F1 Score:  {best_metrics['f1']:.4f}\")\n",
        "print(f\"Training Acc:   {best_metrics['train_acc']:.4f}\")\n",
        "\n",
        "# Show confusion matrix for best model\n",
        "print(f\"\\nConfusion Matrix ({best_model_name}):\")\n",
        "cm = confusion_matrix(y_test, best_metrics['predictions'])\n",
        "print(cm)\n",
        "\n",
        "print(f\"\\nClassification Report ({best_model_name}):\")\n",
        "print(classification_report(y_test, best_metrics['predictions'], target_names=['No Pothole', 'Pothole']))\n",
        "\n",
        "# Save the best model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if best_model_name == '1D-CNN':\n",
        "    cnn_model.save('best_pothole_detection_model_cnn.h5')\n",
        "    print(f\"‚úì Best model saved as 'best_pothole_detection_model_cnn.h5'\")\n",
        "else:\n",
        "    joblib.dump(results[best_model_name]['model'], f'best_pothole_detection_model_{best_model_name.lower()}.joblib')\n",
        "    print(f\"‚úì Best model saved as 'best_pothole_detection_model_{best_model_name.lower()}.joblib'\")\n",
        "\n",
        "# Save all models\n",
        "for model_name, model_data in results.items():\n",
        "    if model_name != '1D-CNN':\n",
        "        filename = f'pothole_model_{model_name.lower()}.joblib'\n",
        "        joblib.dump(model_data['model'], filename)\n",
        "        print(f\"‚úì {model_name} saved as '{filename}'\")\n",
        "\n",
        "# Save the scaler\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "print(\"‚úì Scaler saved as 'scaler.joblib'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a0Uq1F_hHo6",
        "outputId": "420f04d8-4e3f-4f6b-89f0-f3fd3ff4ab24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    }
  ]
}